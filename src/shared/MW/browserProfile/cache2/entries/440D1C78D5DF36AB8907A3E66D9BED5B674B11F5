[{"data":{"person":{"learner":{"programs":[{"programId":"c4cc7072aa4e0d5b5b16e723bdbce38d","liveSeminarDisplayAddToCalendar":true,"__typename":"Program"}],"course":{"title":"SchweserNotes - Book 1","rules":{"allowBookmarks":true,"showGlossaryNavIcon":false,"__typename":"CourseRules","showGlossaryToolTip":false},"__typename":"Course","nodes":[{"nodeId":4740658,"activity":{"activityId":18941,"name":"Module 4.1 Study - Types of Learning and Overfitting Problems","isComplete":false,"nextActivity":{"activityId":18942,"name":"Module 4.1 Quiz","durationMinutes":15,"markedForReview":false,"isAccessible":true,"expectedDate":null,"__typename":"Activity"},"__typename":"Activity"},"quizRules":null,"lineage":[{"nodeId":4740625,"__typename":"Node"},{"nodeId":4740654,"__typename":"Node"},{"nodeId":4740655,"__typename":"Node"}],"title":"Module 4.1: Types of Learning and Overfitting Problems","userStats":{"isBookmarked":false,"bookmarkNote":null,"__typename":"NodeUserStats","isComplete":false},"__typename":"Node","rules":{"hideVideos":false,"__typename":"NodeRules","timeAccruedUponCompletion":false,"canShowMarkComplete":true},"content":{"contentText":"<!--Merge in subtopics.-->\n<h3>LOS 4.a: Describe supervised machine learning, unsupervised machine learning, and deep learning.</h3><p outputclass=\"CFAI_ref\">CFA<sup>¬Æ</sup> Program Curriculum, Volume 1, page 254</p><p><strong>Supervised learning</strong> uses labeled training data to guide the ML program toward superior forecasting accuracy. To identify earnings manipulators, for example, a large collection of attributes could be provided for known manipulators and for known nonmanipulators. A computer program could then be used to identify patterns that identify manipulators in another data set. Multiple regression (discussed in an earlier topic review) is an example of supervised learning. Typical tasks for supervised learning include classification and regression. If the target variable is continuous, the model involved is a regression model. Classification models are used in cases where the target variable is categorical or ordinal (e.g., ranking). Algorithms can be designed for binary classification (e.g., classifying companies as likely to default vs. not likely to default) or multicategory classification (e.g., a ratings class for bonds). </p><p>In <strong>unsupervised learning</strong>, the ML program is not given labeled training data; instead, inputs (i.e., features) are provided without any conclusions about those inputs. In the absence of any target variable, the program seeks out structure or interrelationships in the data. Clustering is an example of an unsupervised ML program. </p><p><strong>Deep learning</strong> algorithms are used for complex tasks such as image recognition, natural language processing, and so on. Programs that learn from their own prediction errors are called <strong>reinforced learning</strong> algorithms. Both of these kinds of algorithms are based on <strong>neural networks</strong>, a group of ML algorithms applied to problems with significant nonlinearities. We will discuss these kinds of algorithms in detail in a later LOS.</p><p>¬†<strong>ML Algorithm Types</strong> summarizes the suitability of various ML algorithms.</p><div id=\"fig_1_cfaL3_topic_00224_4\"><p><em>ML Algorithm Types</em></p><p><table cellpadding=\"5\" frame=\"hsides\" border=\"1\" bordercolor=\"#000000\" rules=\"none\"><tr><th bgcolor=\"#cccccc\" align=\"center\"/><th bgcolor=\"#cccccc\" align=\"center\" class=\"border_bottom\" colspan=\"2\">ML Algorithm Type</th></tr><tr class=\"border_bottom\"><th bgcolor=\"#cccccc\" align=\"left\" valign=\"bottom\">Variables</th><th bgcolor=\"#cccccc\" align=\"center\" valign=\"bottom\"><p>Supervised</p><p>(Target Variable)</p></th><th bgcolor=\"#cccccc\" align=\"center\" valign=\"bottom\"><p>Unsupervised</p><p>(No Target Variable)</p></th></tr><tr><td><strong>Continuous</strong></td><td><p><strong>Regression</strong></p><ul><li>Linear; Penalized Regression/LASSO</li><li>Logistic</li><li>Classification and Regression Tree (CART)</li><li>Random Forest</li></ul></td><td><p><strong>Dimensionality Reduction</strong></p><ul><li>Principal Components Analysis (PCA)</li></ul><p><strong>Clustering</strong></p><ul><li>K-Means</li><li>Hierarchical</li></ul></td></tr><tr><td><strong>Categorical</strong></td><td><p><strong>Classification</strong></p><ul><li>Logit</li><li>Support Vector Machine (SVM)</li><li>K-Nearest Neighbor (KNN)</li><li>Classification and Regression Tree (CART)</li></ul></td><td><p><strong>Dimensionality Reduction</strong></p><ul><li>Principal Components Analysis (PCA)</li></ul><p><strong>Clustering</strong></p><ul><li>K-Means</li><li>Hierarchical</li></ul></td></tr><tr><td><strong>Continuous or Categorical</strong></td><td><p>Neural Networks</p><p>Deep Learning</p><p>Reinforcement Learning</p></td><td><p>Neural Networks</p><p>Deep Learning</p><p>Reinforcement Learning</p></td></tr></table></p><p outputclass=\"source\">Source: 2020 Level II CFA<sup>¬Æ</sup> Program Curriculum, Volume 1, page 468, ¬©2019, CFA Institute</p></div><p>¬†<strong>Choice of Appropriate ML Algorithm</strong> shows the steps involved in selecting the appropriate ML algorithm to use, based on the problem to be solved and the characteristics of the data.</p><div id=\"fig_2_cfaL3_topic_00224_4\"><p><em>Choice of Appropriate ML Algorithm</em></p><p><em>Step 1</em>: Decide if the data set is complex (too many features). If so, apply a dimension reduction algorithm before proceeding to step 2.</p><p><em>Step 2</em>: Decide if the problem is that of classification. If yes, go to step 3. If no, (i.e., it is a numerical prediction problem):</p><ul><li>Use penalized regression if the data is linear.</li><li>Or, for nonlinear and complex data, use CART, random forests, or neural networks.</li></ul><p><em>Step 3</em>: Is it supervised classification? If no, go to step 4. For supervised classification:</p><ul><li>For linear data, use KNN or SVM. </li><li>For complex nonlinear data, use CART, random forests, or neural networks.</li></ul><p><em>Step 4</em>: For unsupervised classification:</p><ul><li>For linear data, use <em>k</em>-means if the number of categories is known. If the number of categories is not known, use hierarchical clustering.</li><li>For complex nonlinear data, use neural networks.</li></ul><p>We will discuss these ML algorithms in the remainder of this topic review.</p></div><h3>LOS 4.b: Describe overfitting and identify methods of addressing it.</h3><p outputclass=\"CFAI_ref\">CFA<sup>¬Æ</sup> Program Curriculum, Volume 1, page 259</p><p><strong>Overfitting</strong> is an issue with supervised ML that results when a large number of features (i.e., independent variables) are included in the data sample. Overfitting has occurred when the noise in the target variables seems to improve the model fit (i.e., randomness is misperceived to be a pattern, resulting in high in-sample R-squared). Overfitting the model will decrease the accuracy of model forecasts on other (out-of-sample) data‚Äîoverfit models do not <strong>generalize</strong> well to new data (i.e., out-of-sample R-squared will be low). </p><div style=\"margin-left:30px; margin-right:50px;\"><p><strong>Professor's Note</strong></p><p>When a model generalizes well, it means that the model retains its explanatory power when it is applied to new (i.e., out-of-sample) data.</p></div><p>To measure how well a model generalizes, data analysts create three nonoverlapping data sets: (1) <strong>training sample</strong> (used to develop the model), (2) <strong>validation sample</strong> (used for tuning the model), and (3) <strong>test sample</strong> (used for evaluating the model using new data). In-sample prediction errors occur with the training sample, while prediction errors in the validation and test samples are known as the out-of-sample errors. Data scientists then decompose these errors into the following:</p><ul><li><strong>Bias error</strong>. This is the in-sample error resulting from models with a poor fit.</li><li><strong>Variance error</strong>. This is the out-of-sample error resulting from overfitted models that do not generalize well.</li><li><strong>Base error</strong>. These are residual errors due to random noise.</li></ul><p>A <strong>learning curve</strong> plots the accuracy rate (i.e., 1 ‚àí error rate) in the validation or test sample versus the size of the training sample. A robust, well-generalizing model will show an improving accuracy rate as the sample size is increased, and the in-sample and out-of-sample error rates will converge toward a <em>desired </em>accuracy level, as shown in the third panel of ¬†<strong>Accuracy Rate Patterns</strong>. Models with high bias error (first panel) will see the error rates converge, but far below the desired level. Models with high variance error (second panel) will see only the in-sample accuracy rate converge toward the desired level, while the out-of-sample accuracy rate lags far behind.</p><div id=\"fig_1_cfaL3_topic_00224_5\"><p><em>Accuracy Rate Patterns</em></p><p product=\"digital\"><img src=\"https://static.kaplanlearn.com/assets/3a/77/CFA_R7_image1.jpg\" alt=\"\"/></p></div><p>Variance error increases with model complexity, while bias error decreases with complexity. Data scientists often express this as a tradeoff between <em>cost</em> and <em>complexity</em>. An optimal level of complexity minimizes the total error and is a key part of successful model generalization.</p><p>To reduce the problem of overfitting, data scientists use complexity reduction and cross validation. In complexity reduction, a penalty is imposed to exclude features that are not meaningfully contributing to out-of-sample prediction accuracy. This penalty value increases with the number of independent variables (features) used by the model.</p><p>For a model to learn sufficiently, researchers must ensure that the training data set is both large and representative of the population. The validation sample, similarly, should be large and representative to properly test the model. A sampling technique known as <strong>cross validation</strong> estimates out-of-sample error rates directly from the validation sample.</p><p>In a <strong>k-fold cross validation</strong>, the sample is randomly divided equally into <em>k</em> parts. The training sample comprises (k ‚àí 1) parts, with one part left for validation. Error is then measured for the model in each of the parts. This process is repeated <em>k</em> times, and the average in-sample and out-of-sample error rates are compiled.</p><div id=\"VideoPlayerContainer\" role=\"region\" aria-label=\"Video Player region\" aria-live=\"polite\"><div id=\"video_player_5287099843477504\"><div id=\"player_6085306117001\" style=\"margin-top: 10px;\"><param name=\"allowScriptAccess\" value=\"always\" /></div></div></div><br/>","__typename":"Content"},"video":{"title":"Module 4.1: Types of Learning and Overfitting Problems","ucmsId":"5287099843477504","videoId":"6085306117001","enrollmentDetail":{"enrollmentDetailId":56872514,"__typename":"EnrollmentDetail"},"channel":{"channelId":56872514,"__typename":"VideoChannel"},"playerInstance":"jwplayer","accountId":"2974989255001","maxPosition":0,"playerId":"muVZWdr95","currentPosition":0,"mediaForceProgression":false,"mediaForceProgressionPercentage":0,"playerKey":"wJZUYvXlc/swMq+Y8AV5HwCIO9HjA2HYyguwqedGGC4=","playerScripts":["https://static.kaplanlearn.com/js/jwplayer/jwplayer.js","https://static.kaplanlearn.com/js/jwplayer/plugins/thegovernor/thegovernor.js","https://static.kaplanlearn.com/js/ucms-player.js"],"type":"embedded","thumbnailUrl":"http://f1.media.brightcove.com/8/2974989255001/2974989255001_6085306947001_6085306117001-vs.jpg?pubId=2974989255001&videoId=6085306117001","isPending":false,"isLive":false,"startDate":null,"duration":1141,"presenter":null,"details":null,"sources":[{"url":"https://kaplanudso.akamaized.net/2974989255001/2974989255001_6085311941001_6085306117001.mp4?pubId=2974989255001&videoId=6085306117001","label":"1280x720 @ 991kbps","rate":"991000","__typename":"VideoSource"},{"url":"https://kaplanudso.akamaized.net/2974989255001/2974989255001_6085311042001_6085306117001.mp4?pubId=2974989255001&videoId=6085306117001","label":"720x404 @ 726kbps","rate":"726000","__typename":"VideoSource"},{"url":"https://kaplanudso.akamaized.net/2974989255001/2974989255001_6085308225001_6085306117001.mp4?pubId=2974989255001&videoId=6085306117001","label":"640x360 @ 595kbps","rate":"595000","__typename":"VideoSource"}],"tracks":[{"default":false,"url":"https://ucms.kaplan.com/caption/agxzfmthcGxhbnVjbXNyMAsSBlJlY29yZBiAgMDg7ZKyCQwLEhBCYXNlSG9zdGVkUmVjb3JkGICAwODvhdcJDA","label":"English","kind":"captions","__typename":"VideoTrack"}],"playerSkinData":{"fullscreenButton":"https://static.kaplanlearn.com/js/jwplayer/skins/assets/fullscreenButton.png","skin":"https://static.kaplanlearn.com/js/jwplayer/skins/six_flash.xml","__typename":"PlayerSkinData"},"__typename":"Video"},"nextNodeWithContent":{"title":"Module 4.2: Supervised Learning Algorithms","nodeId":4740659,"userStats":{"isAccessible":true,"__typename":"NodeUserStats"},"__typename":"Node"},"previousNodeWithContent":{"title":"Machine Learning","nodeId":4740657,"userStats":{"isAccessible":true,"__typename":"NodeUserStats"},"__typename":"Node"}}],"userStats":{"lastViewedNode":{"nodeId":4740657,"userStats":{"isAccessible":true,"__typename":"NodeUserStats"},"__typename":"Node"},"__typename":"CourseUserStats"}},"__typename":"Learner"},"__typename":"Person"}}}]ëuùyº      a¯OÂa¯OÂCËX˝a¯OÂ   _    O^partitionKey=%28https%2Ckaplanlearn.com%29,a,~1643659271,:https://gql.kaplanlearn.com/graphql necko:classified 1 strongly-framed 1 security-info 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 request-method POST auth Bearer response-head HTTP/2 200 OK
date: Mon, 31 Jan 2022 21:08:53 GMT
content-type: application/json
content-length: 13613
x-powered-by: Express
access-control-allow-origin: *
server-timing: dtRpid;desc="1500073335"
timing-allow-origin: *
X-Firefox-Spdy: h2
 original-response-headers date: Mon, 31 Jan 2022 21:08:53 GMT
content-type: application/json
content-length: 13613
x-powered-by: Express
access-control-allow-origin: *
server-timing: dtRpid;desc="1500073335"
set-cookie: dtCookie=v_4_srv_10_sn_0624F5F4D9118804F08C0A87D9F0FE81_perc_100000_ol_0_mul_1; Path=/; Domain=.kaplan.com; secure
timing-allow-origin: *
X-Firefox-Spdy: h2
 ctid 1 net-response-time-onstart 341 net-response-time-onstop 342   5-